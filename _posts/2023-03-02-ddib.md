---
layout: post
title:  "[리뷰] (DDIB) Dual Diffusion Implicit Bridges for Image-to-Image Translation"
date:   2023-03-02 21:34:00 +0900
categories: [Diffusion Model]
tags: [Diffusion Model, Generative Model, Translation Model]
use_math: true
---

{: .note .warning}
공부하면서 정리한 내용이므로 부정확한 내용이 포함되어 있을 수 있음.

Title: [Dual Diffusion Implicit Bridges for Image-to-Image Translation]
<br/>
Authors: Xuan Su, Jiaming Song, Chenlin Meng, Stefano Ermon
<br/>
Submitted on 28 Feb 2023
<br/>
Github: [Github]

## Abstract

* 일반적인 I2I 변환 (Image-to-Image Translation) 기법은 소스 도메인(source domain)과 타깃 도메인 (target domain) 모두의 데이터에 대한 합동 트레이닝에 의존함.
* 트레이닝 프로세스는 두 데이터셋에 동시에 액세스해야 하므로, 데이터 분리 및 개인 정보 보호에 방해가 되며, 기존 모델들은 새로운 도메인 쌍의 변환에 쉽게 적응할 수 없음.
* 여기서 도메인 쌍에 대한 트레이닝을 우회하는 확산 모델 (Diffusion Model) 기반의 이미지 변환 기법인 Dual Diffusion Implicit Bridge(DDIB)를 제안함.
* DDIB를 사용한 이미지 변환은 각 도메인에서 독립적으로 트레이닝된 두 가지 확산 모델에 의존하며, 2단계로 구성된 프로세스임.
    * DDIB는 먼저 소스 확산 모델로 소스 이미지에 대한 잠재 인코딩(latent encoding)을 얻음.
    * 그 다음, 타깃 모델을 사용하여 이러한 인코딩을 디코딩하여 타깃 이미지를 구성함.
* 두 단계 모두 일반 미분 방정식(ordinary differential equation, ODE)을 통해 정의되므로, 프로세스는 ODE solver의 이산화 오차 이내로만 cycle consistent임.
* 이론적으로, DDIB를 엔트로피 정규화 최적 전송(transport)의 한 형태인 슈뢰딩거 브리지(Schrödinger Bridges)를 대상으로 소스와 잠재의 연결로 해석하여 방법의 효과를 설명한다. 실험적으로, 우리는 합성 및 고해상도 이미지 데이터 세트에 DDIB를 적용하여 광범위한 번역 작업에서 그 유용성과 고유한 최적 전송 특성을 입증한다.

<div id="Fig1"></div>
![Fig1](/assets/ddib/fig1.png)

그림 1: **Dual Diffusion Implicit Bridges**: DDIB는 이미지 변환을 위해 두 ODE를 활용함. 한 소스 이미지 $$\mathbf{x}^{(s)}$$가 주어졌을 때, 소스 ODE는 정방향으로 실행되어 잠재 $$\mathbf{x}^{(l)}$$로 변환하는 반면, 타깃, 즉 역방향 ODE는 타깃 이미지 $$\mathbf{x}^{(t)}$$를 구축함. (상) 두 1차원 분포 사이의 DDIB 아이디어 묘사. (하) 사전 트레이닝된 (pretrained) 조건부 확산 모델(conditional diffusion model)을 사용하여 호랑이에서 고양이로 변환하는 DDIB.

<div id="Sec2"></div>
## Preliminaries

### Score-based Generative Models (SGMs)

* 실제 구현은 DDIM을 활용함으로써, 스코어 기반 생성 모델로 알려진 모델들의 더 광범위한 집합을 간단히 소개함.
    * 이 집합의 대표적인 두 모델은 _score matching with Langevin dynamics_(SMLD)([Song & Ermon, 2019])와 _denoising diffusion probabilistic models_(DDPMs)([Ho et al., 2020])임. 두 기법은 모두 [Song et al. (2020b)]에 제안된 Stochastic Differential Equations (SDEs) 프레임워크 내에 포함됨.
    
* **Stochastic Differential Equation (SDE) Representation**
    * [Song et al. (2020b)], [Anderson (1982)]은 정방향과 그에 상응하는 역방향 SDE를 사용하여 일반적인 확산 및 역방향의 생성 프로세스를 아래와 같이 설명함.
    <br/><br/>
    <div id="Eq1"></div>
    ![Eq1](/assets/ddib/eq1.png)
    <br/><br/>
    여기서 $$\mathbf{w}$$는 표준 Wiener 프로세스이고, $$\mathbf{f}(\mathbf{x}, t)$$는 벡터 값의 drift 계수, $$g(t)$$는 스칼라 확산 계수, $$\nabla_{\mathbf{x}} \log p_t (\mathbf{x})$$는 노이즈로 동요하는 (perturbed) 데이터 분포의 스코어 함수임(초기 조건 $$p_0 (\mathbf{x})$$이 데이터 분포인 정방향 SDE로 정의되어 있듯).
    * 끝점 $$t = \{0, 1\}$$에서, 정방향 [Eq.(1)](#Eq1)은 데이터 분포 $$p_0$$와 샘플링 쉬운 prior $$p_1$$을 경계 분포(boundary distribution)로 받아들임. 이 프레임워크 내에서, SMLD 기법은 _Variance-Exploding_ (VE) SDE를 증가하는 노이즈 스케일 $$\sigma(t)$$와 함께 사용하여 설명될 수 있음. 즉, $$\textup{d}\mathbf{x} = \sqrt{\textup{d}[\sigma^2 (t)] / \textup{d}t} \textup{d}\mathbf{w}$$임.
    * 그에 비해, DDPM은 _Variance-Preserving_ (VP) SDE가 부여됨. 즉, $$\beta (t)$$는 또 다른 노이즈 시퀀스인 $$\textup{d}\mathbf{x} = -[\beta (t) / 2]\mathbf{x} \textup{d}t + \sqrt{\beta (t)}\textup{d}\mathbf{w}$$임. 주목할 만한 것은, 이 VP SDE는 동등한 VE SDE 안에 다시 파라미터화될 수 있다는 점임([Song et al., 2020a]).
<br/><br/>
* **Probability Flow ODE**
    * 어떤 확산 프로세스든 궤적 전체에 걸쳐 확산 프로세스와 동일한 marginal density를 전달하는 _deterministic_ ODE로 표현될 수 있음. 이 ODE를 _probability flow_ (PF) ODE라고 함([Song et al., 2020b]).
    * PF ODE는 데이터의 _고유하게 식별 가능한 인코딩_([Song et al., 2020b])을 가능하게 하며, 데이터와 잠재 사이의 정방향 및 역방향 변환을 위해 이러한 ODE를 해결할 때 DDIB의 중심이 됨. 
    * [Eq.(1)](#Eq1)에 도입된 정방향 SDE에 대하여, 동등한 PF ODE는 다음 형태를 유지함.
    <br/><br/>
    <div id="Eq2"></div>
    ![Eq2](/assets/ddib/eq2.png)
    <br/><br/>
    이것은 스코어 함수가 주어진 SDE로부터 즉시 이어짐.
    * 실제로, $$\theta$$로 파라미터화된 스코어 네트워크 $$\mathbf{s}_{t, \theta} \approx \nabla_x \log p_t (\mathbf{x})$$를 사용하여 스코어 함수를 근사함. 그러한 네트워크를 트레이닝하는 것은, [Ho et al. (2020)] 및 부록 B에서 설명한 것과 같이 가변의 하한에 의존함.
    * 그러면 수치상의 ODE solver를 차용하여 위 ODE를 풀고 여러 시간대에서 $$\mathbf{x}$$를 구성함. 경험상으로, SGM은 ODE solver를 통해 $$t = 0$$에서 $$\mathbf{x}$$를 재구성할 때 상대적으로 discretization 오차를 가진다는 점이 확인됨([Song et al., 2020a]).
    * 간결하게, $$v_\theta = \textup{d}\mathbf{x} / \textup{d}t$$를 $$\theta$$로 파라미터화된 속도 필드를 나타내는 데 사용하고([Eq.(2)](#Eq2)에 정의된 것처럼, $$\nabla_x \log p_t (\mathbf{x})$$를 $$\mathbf{s}_{t, \theta}$$로 대체), 심벌 ODESolve를 $$\mathbf{x}( t_0 )$$에서 $$\mathbf{x}( t_1 )$$으로 매핑하는 데 사용함.
    <br/><br/>
    <div id="Eq3"></div>
    ![Eq3](/assets/ddib/eq3.png)
    <br/><br/>
    이를 통해 정확한 모델(스코어 기반이나 확산 모델), 또는 사용된 적분기(integrator)를 추상화할 수 있음.
    * 실험에서, DDIM([Song et al., 2020a])(부록 B)에서 ODE solver를 구현함. 또한, DPM solver([Lu et al., 2022]), 지수 적분기([Zhang & Chen, 2022]) 및 2차 Heun solver([Karr et al, 2022])와 같은 우리의 프레임워크 내에서 사용 가능한 다른 ODE solver도 인정함.

### Schrödinger Bridge Problem (SBP)

* 본 분석은 DDIB가 분포들 사이의 슈뢰딩거 브리지([Chen et al., 2016], [Léonard, 2013])임을 보임.
* $$\Omega = C([0, 1]; \mathbb{R}^n )$$을 시간 구간 $$[0, 1]$$에 걸친 $$\mathbb{R}^n$$ 값의 연속함수의 경로 공간이라 하고, $$\mathcal{D}(p_0, p_1)$$를 각각 $$t = 0, t = 1$$에서의 한계점 $$p_0, p_1$$의 $$\Omega$$에 걸친 분포의 집합이라 함.
* Prior reference measure $$W$$이 주어졌을 때, 잘 알려진 슈뢰딩거 브리지 문제(SBP)는 한계점 $$p_0, p_1$$ 사이에서 시간 $$t$$에 걸친 가장 가능성 있는 진화(evolution)를 찾음.
<br/><br/>
**문제 1** (슈뢰딩거 브리지 문제) 상술한 분포 $$p_0, p_1$$과 prior로서의 reference measure $$W$$가 주어졌을 때, SBP는 $$\mathcal{D}(p_0, p_1)$$으로부터 $$W$$에 대한 KL 발산(divergence)을 최소화하는 분포를 찾음: $$P_{SBP} := \arg \min\{D_{KL}(P || W) \vert P \in \mathcal{D}(p_0, p_1)\}$$
<br/><br/>
* Minimizer $$P_{SBP}$$는 prior $$W$$에 걸친 $$p_0$$과 $$p_1$$ 사이의 슈뢰딩거 브리지라고도 불림. 이 SBP는 Monge-Kantorovich (MK) 최적 전송 문제와 연결점이 있음([Chen et al., 2021b]). 기본 MK 문제가 분포들 사이의 데이터들을 전송하는 데 비용을 최소화하는 계획을 찾는다면, SBP는 추가적인 엔트로피 항을 통합함(세부 내용은 **Computational Optimal Transport: With Applications to Data Science**(Peyré 저)의 61쪽 참고).

* **SBP와 SGM의 관계**
    * [Chen et al., 2021a]는 SGM와 SBP 사이의 연결점을 설립함. 요약하면, SGM은 linear 또는 degenerate drift의 SBP에 대응하는 암시적 최적의 전송 모델임. 일반적인 SBP는 추가적으로 완전 nonlinear 확산을 수용함.
    * 이 관찰을 공식화하기 위해, 저자들은 먼저 SBP를 위한 유사한 정방향 및 역방향 SDE를 아래와 같이 설립함.
    <br/><br/>
    <div id="Eq4"></div>
    ![Eq4](/assets/ddib/eq4.png)
    <br/><br/>
    여기서 $$\Phi, \hat{\Phi}$$는 밀도 factorization $$p_t (\mathbb{x}) = \Phi_t(\mathbb{x})\hat{\Phi}_t(\mathbb{x})$$

## Dual Diffusion Implicit Bridges

* DDIB는 SGM과 SBP 사이의 연결점을 활용하여 I2I 변환을 수행하는데, 두 확산 모델은 두 도메인에서 따로 트레이닝됨.
* DDIB는 알고리즘 1과 그림 1에서 설명되어 있음. 이 알고리즘의 핵심은 [Eq.(3)](#Eq3)의 ODE solver ODESolve임.
    * [Eq.(2)](#Eq2)로부터 정의된 벡터 필드로 표현된 소스 모델, 즉 $$v_\theta^{(s)}$$가 주어졌을 때, DDIB는 먼저 소스 도메인에서 ODESolve를 적용하여 시간 $$t = 1$$의 끝에서 이미지의 인코딩 $$\mathbf{x}^{(s)}$$을 얻음. 이것을 (해당 도메인에 대한 확산 모델과 연관된) 잠재 코드(latent code)라 칭함.
    * 그리고, 소스 잠재 코드는 초기 조건($$t = 1$$에서의 타깃 잠재 코드)으로 타깃 모델 $$v_\theta^{(t)}$$과 함께 ODESolve에 입력되어 타깃 이미지 $$\mathbf{x}^{(t)}$$를 얻음.
* 상술했듯이, ODESolve는 DDIM과 함께 구현되는데, 이것은 꽤 작은 discretization 오차를 가지고 있는 것으로 알려져 있음. DDIM을 일반화하는 고차 ODE solver에서의 최근 발전도 여기서 사용될 수 있으며, 이 고찰은 추후 연구로 고려될 수 있겠음.
<br/><br/>
* **정확한 Cycle Consistency**
    * 이미지 변환 알고리즘의 원하는 특징은 _cycle consistency_ 특성임. 한 데이터 포인트를 소스 도메인에서 타깃 도메인으로 변형하고, 다시 소스 도메인으로 되돌리면, 소스 도메인에서의 원본 데이터 포인트로 복귀되는 것임. 다음 제의는 DDIB의 cycle consistency를 유효화함.
    <br/><br/>
    **제의 3.1** (DDIB는 정확한 Cycle Consistency를 강제함) 소스 도메인으로부터 한 샘플 $$\mathbf{x}^{(s)}$$, 소스 확산 모델 $$v_\theta^{(s)}$$, 타깃 모델 $$v_\theta^{(t)}$$이 주어졌을 때, 아래를 정의함.
    <br/><br/>
    <div id="Eq7"></div>
    ![Eq7](/assets/ddib/eq7.png)
    <div id="Eq8"></div>
    ![Eq8](/assets/ddib/eq8.png)
    <br/><br/>
    Discretization 오차는 0으로 가정함. 따라서, $$\mathbf{x}^{(s)} = \mathbf{x}^{\prime(s)}$$임.
    <br/><br/>
    * PF ODE가 사용됨으로써, cycle consistency 특성은 보장됨. 현실적으로, discretization 오차가 있어도, DDIB는 거의 무시해도 될 정도의 cycle inconsistency를 유발함. 반면, GAN 기반의 기법들은 디폴트적으로 cycle consistency 특성을 보장받지 못하고, 두 도메인에 걸친 cycle consistency에 대해 최적화할 추가적인 트레이닝 항을 통합해야 함.
<br/><br/>
* **두 도메인에서의 데이터 프라이버시**
    * DDIB 번역 프로세스에서는 소스 및 타깃 확산 모델만 필요하며, 훈련 프로세스는 도메인 쌍 a priori에 대한 지식에 의존하지 않는다. 실제로 이 프로세스는 개인 정보 보호에 민감한 방식으로 수행될 수도 있다(부록 A의 그래픽 그림). Alice와 Bob을 각각 소스 도메인과 타깃 도메인의 데이터 소유자로 지정합니다. Alice가 이미지를 타깃 도메인으로 변환하려고 한다고 가정합니다. 그러나 Alice는 Bob과 데이터를 공유하고 싶지 않습니다(Bob도 데이터를 공개하고 싶지 않습니다). 그런 다음 앨리스는 소스 데이터로 확산 모델을 훈련시키고, 데이터를 잠재 공간으로 인코딩한 다음, 잠재 코드를 밥에게 전송하고, 밥에게 훈련된 확산 모델을 실행하고 결과를 다시 전송하도록 요청할 수 있다. 이 절차에서는 두 데이터 공급업체 간에 잠재 코드와 타깃 결과만 전송되며, 양측 모두 데이터가 직접 노출되지 않도록 자연스럽게 보장했다.
<br/><br/>
* **DDIB는 두 개의 연결된 슈뢰딩거 브리지**
    * DDIB는 소스 데이터 분포를 잠재 공간에 연결한 다음, 타깃 분포에 연결함.
    * 분포 사이의 그러한 연결의 본질은 무엇인가? 최적의 운송 관점에서 답을 제공함. 이러한 연결은 분포 사이의 특별한 슈뢰딩거 브리지임.
    * 다음으로 본 기법의 이름을 설명함. DDIB은 디노이징 확산 암시 모델(denoising diffusion implicit model)을 기반으로 하며([Song et al., 2020a]), 데이터와 잠재 분포를 연결하는 두 개의 개별 슈뢰딩거 브리지로 구성됨.
    * 특히, 앞서 고려한 바와 같이, [Eq.(5)](#Eq5)에서의 정책들 $$\mathbf{z}_t, \hat{\mathbf{z}}_t$$ 및 가우시안 prior 밀도 $$p_{1}(x)$$에 대한 조건이 충족될 때, SGM과 SBP에 대한 데이터 likelihood($$t = 0$$에서)는 동일함. 실제로, 이러한 조건은 SGM, 특히 DDIM에서 충족됨. 이것은 SGM을 special linear 또는 degenerate SBP로 검증함.
    * DDIB에서와 같이, SGM를 위한 PF ODE를 정방향 및 역방향으로 푸는 것은 특정 SBP의 최적 프로세스를 통해 흐르는 것과 동등함.
    <br/><br/>
    **제의 3.2** (PF ODE 동등성). [Eq.(2)](#Eq2)는 SGM, 특히 DDIM에서 달성된 것처럼, 정방향, 역방향 정책들 $$(\mathbf{z}_t, \hat{\mathbf{z}}_t) = (0, g\nabla_x \log p_t (\mathbf{x}))$$을 갖는 [Eq.(6)](#Eq6)와 동등함.
    <br/><br/>
    * 따라서 DDIB는 본질적으로 엔트로피 정규화된 최적 전송임. 이것은 소스와 잠재 사이 및 잠재와 타깃 분포 사이의 슈뢰딩거 브리지임. 그 다음 변환 프로세스는 하나의 정방향과 하나의 역방향인 두 개의 결합된 슈뢰딩거 브리지를 통과하는 것으로 인식될 수 있음.
    * 매핑은 고유하며 (정규화된) 최적 전송 목적(objective)을 최소화하는데, 이는 아마도 DDIB의 우수한 성능을 설명할 것임.
    * 반면, 그러한 연결을 가지고 생기지 않은 흐름 모델을 normalize 하면서 소스 모델과 타깃 모델을 별도로 트레이닝한다면, 실행 가능한 invertible 매핑이 많고, 결과 이미지 변환 알고리즘이 반드시 좋은 성능을 가지지 않을 수 있음. 이것이 아마도 AlignFlow([Grover et al., 2020])가 cycle consistency가 보장되는 경우에도 adversarial loss를 통합해야 하는 이유일 것임.

## Experiments

* DDIB의 효과를 설명하기 위한 일련의 실험을 제시함.
    * 먼저 2차원 데이터셋에서 합성 실험을 설명하여, DDIB의 cycle-consistent하고 최적인 전송 속성을 제공함.
    * 그 다음, DDIB를 색 변화, 짝지어진 변환, 조건부 ImageNet 변환을 포함한, 다양한 이미지 변환 task에서 유효화함.

### 2D Synthetic Experiments

<div id="Fig2"></div>
![Fig2](/assets/ddib/fig2.png)

그림 2: DDIB의 매끄러움 및 cycle consistency. (a) 합성 데이터셋의 매끄러운 변환. (좌) 소스 데이터셋: CR, CS. (중) DDIB의 잠재 코드 표현. (우) 타깃 도메인으로의 변환 결과. (b) **Cycle consistency**: Moons에서 Checkerboards로, 다시 Moons로 복귀 변환 후, DDIB는 원본 포인트들을 거의 정확히 복구함.

<div id="Table1"></div>
![Table1](/assets/ddib/table1.png)

표 1: DDIB의 cycle consistency. 실험 범례, PR $$\circlearrowright$$ PS는 PR에서 PS로 그리고 반대로 변환한다는 의미임. 수치들은 원본 포인트들과 순환 변환 후 좌표들 사이의 평균 L2 거리임. 데이터 포인트들은 단위 분산으로 표준화됨.

* 먼저 [그림 2a](#Fig2)에서 다양한 모양과 구성을 가진 복잡한 2차원 분포에서 도출된 합성 데이터셋에 대해 도메인 변환을 수행함.
* 총 6개의 2D 데이터셋을 고려함: Moons (M); Checkerboards (CB); Concentric Rings (CR); Concentric Squares (CS); Parallel Rings (PR); and Parallel Squares (PS).
* 데이터셋은 모두 평균이 0, 공분산(covariance)이 $$I$$(identity)가 되도록 정규화됨.
* 포인트 ID를 기반으로 포인트에 색을 할당함(즉, 소스 도메인의 포인트가 빨간색이면, 타깃 도메인의 해당 포인트도 빨간색).
* 분명히, 열 간의 변형은 매끄러움. 예를 들어, 우상 구석에서, CR 데이터셋의 빨간 포인트들은 잠재 차원 및 타깃 차원에서, 비슷한 좌표에 매핑됨.
<br/><br/>
* **Cycle Consistency**
    * [그림 2b](#Fig2)는 DDIB로 보장되는 cycle consistency 속성을 나타냄. 2D 데이터셋 Moons와 Checkerboards와 관련이 있음.
    * Moons 데이터셋에서 시작하여, DDIB는 먼저 잠재 코드를 업고 Checkerboards 포인트를 구축함. 다음, DDIB는 역방향으로 변환을 수행하는데, 포인트들을 잠재 공간 및 Moons 공간으로 되돌림. 이러한 왕복 후, 포인트들은 원래 위치로 대략적으로 매핑됨. 이 실험에서 비슷하고 매끄러운 색 topology가 관찰됨.
    * [표 1](#Table1)은 다수의 데이터셋 사이에서 cycle-consistent 변환에 대한 양적 측정 결과를 보여 줌. 데이터들이 단위 표준편차로 정규화되어, 나타난 값들은 무시할 수 있을 정도로 작고 DDIB의 cycle consistency 속성을 보중함.

### Example-Guided Color Transfer

* DDIB는 흥미로운 응용에 사용될 수 있음: example-guided color transfer. 이것은 인풋 이미지의 색을 변경하는 task를 말하는데, 이는 레퍼런스 이미지의 색 팔레트로 조건화되어 있음.
* 색 변화로 DDIB를 사용하기 위해, 이미지 당, 정규화된 RGB 공간에서 확산을 트레이닝함.
* 변환 동안, DDIB는 원 색상의 인코딩을 얻고, 레퍼런스 이미지의 확산 모델을 적용하여 원하는 색 팔레트를 취득함. [그림 3](#Fig3)은 본 색 실험을 시각화함.

## Conclusions

* 스코어 기반의 확산 모델의 최근 진전에서 비롯된 새롭고 간단한 이미지 변환 기법인 Dual Diffusion Implicit Bridge(DDIB)를 제안하며, 이것은 이미지 공간에서 슈뢰딩거 브리지로서 이론적으로 기반을 두고 있음.
* DDIB는 두 가지 주요 문제를 해결함.
    * 주어진 도메인 쌍에서만 특정 결합 loss에 대한 최적화를 회피함.
    * 트레이닝 중에 더 이상 두 데이터셋의 존재를 필요로 하지 않으므로, 데이터셋 프라이버시를 더 잘 보호함.
* 강력한 사전 트레이닝된 확산 모델들은 본 DDIB 프레임워크에 통합되어, 도메인 변환에서 DDIB의 실제 가치를 증명하는 포괄적인 일련의 실험을 수행함.
* 본 기법은 각 이미지에 대해 하나의 모델이 필요하기 때문에, 색상 전환에 적용하는 데 한계가 있으며, 이는 대량 실험에서는 상당한 계산량을 요구함.
* 최적의 전송에 기반을 둔, DDIB 변환은 때때로 문제가 될 수 있는 대량 이동 프로세스를 모방함.
* 향후 연구는 이러한 문제들을 해결하거나, 소스 도메인과 타깃 도메인의 다른 차원들로 확장 응용할 수 있음.
* 결합된 ODE를 통해 진행하는 것은 시간이 많이 걸리기 때문에, 변환 속력을 개선하는 것도 유망한 방향임.


[Dual Diffusion Implicit Bridges for Image-to-Image Translation]: https://openreview.net/forum?id=5HLoTvVGDe
[Github]: https://github.com/suxuann/ddib
[Léonard, 2013]: https://arxiv.org/abs/1308.0215